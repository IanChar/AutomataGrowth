{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this first!!!\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('../common')\n",
    "import util\n",
    "import sampling_misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "The goal now is to find $\\mu_X$ and $\\mu_Y$ for the size model. It seems like $\\mu_X$ should be the easiest so we start there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Subproblem\n",
    "\n",
    "A good place to potentially start is looking at the probability that any one state will have a child that is a new thread. Let $X_{i, n}$ take the value of 1 if the $i^{th}$ state in depth $n$ has a child that is a new thread and 0 otherwise.\n",
    "\n",
    "Recall that to find the failure of a child, we look at the parent's failure and see if we can advance in the DFA from that point. If not, we keep following the \"failure chain\" until we can find a point in which we can go forward. Therefore, we know we have a new thread if we have to follow the failure chain all the way back to the root state and then we are able to go forward from this point.\n",
    "\n",
    "From this it becomes clear that the number of failures in the failure chain plays an important role. As such let $F_{i, n}$ be the number of failures in the failure chain for the $i^{th}$ state in depth $n$. For now let's assume some arbitrary value for this to see if we can derive the probability for this without having to worry about this.\n",
    "\n",
    "For some alphabet $\\Sigma$ we let $p_\\sigma$ be the probability of seeing letter $\\sigma$ in one of the sets in the generalized string $G$. With this established let's think about the aforementioned way that we can tell that something will be a new thread. Really we can think about this whole thing as a (slightly altered) geometric distribution since each time we go to another link in the failure chain we see if we can go forwards and stop if we can. This is slightly altered since the geometric can only take on finite values ($ \\leq F_{i, n}$). This actually won't change anything because all of the other mass will be concentrated at some other point and can be ignored. So something has a new thread if for some $\\sigma \\in \\Sigma$ the slightly altered geometric random variable is equal to $F_{i, n}$. That is...\n",
    "\n",
    "$$\n",
    "P(X_{i, n} | F_{i, n} = f) = \\sum_{A \\subseteq \\Sigma} \\left(1 - P\\left(\\textrm{There is no $\\sigma \\in \\Sigma$ such that } Geom(p_\\sigma) = f\\right) \\right) P(A)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\sum_{A \\subseteq \\Sigma} \\left(1 - \\prod_{\\sigma \\in A} \\left(1 - (1 - p_\\sigma)^{m - 1} p_\\sigma \\right) \\right) P(A)\n",
    "$$\n",
    "\n",
    "Where\n",
    "\n",
    "$$\n",
    "P(A) = \\prod_{\\sigma \\in A} p_\\sigma \\prod_{\\sigma \\in \\Sigma \\setminus A} (1 - p_\\sigma)\n",
    "$$\n",
    "\n",
    "Simulating this below, we see that this looks like the correct expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_theoretical(probs, m):\n",
    "    return _expand_possibilities(probs, m)\n",
    "\n",
    "def _expand_possibilities(probs, m, curr=None, index=0):\n",
    "    if curr is None:\n",
    "        curr = [False for _ in range(len(probs))]\n",
    "    if index == len(probs):\n",
    "        return _get_theor_term(probs, m, curr)\n",
    "    nxt = list(curr)\n",
    "    nxt[index] = True\n",
    "    return (_expand_possibilities(probs, m, nxt, index + 1)\n",
    "            + _expand_possibilities(probs, m, curr, index + 1))\n",
    "\n",
    "def _get_theor_term(probs, m, subset):\n",
    "    if True not in subset:\n",
    "        return 0\n",
    "    prob_f = 1\n",
    "    prob_x = 1\n",
    "    for i, include in enumerate(subset):\n",
    "        p = probs[i]\n",
    "        if include:\n",
    "            prob_f *= p\n",
    "            prob_x *= (1 - (1 - p) ** (m - 1) * p)\n",
    "        else:\n",
    "            prob_f *= (1 - p)\n",
    "    return (1 - prob_x) * prob_f\n",
    "\n",
    "def compare(probs, m, num_samples, depth):\n",
    "    theor = get_theoretical(probs, m)\n",
    "    df = sampling_misc.sample_state_has_new_thread(num_samples, probs, depth, [m])\n",
    "    sampled = df['has_new_thread'].mean()\n",
    "    print 'Theoretical: %f' % theor\n",
    "    print 'Sampled: %f' % sampled\n",
    "    print 'Relative Error: %f' % (abs(sampled - theor) / theor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theoretical: 0.413818\n",
      "Sampled: 0.409091\n",
      "Relative Error: 0.011424\n"
     ]
    }
   ],
   "source": [
    "# PARAMETERS\n",
    "PROBS = [0.5 for _ in range(4)] # Probability of seeing each letter.\n",
    "NUM_SAMPLES = 100\n",
    "DEPTH = 20 # Depth to check state at\n",
    "M = 2 # Size of parent\n",
    "\n",
    "compare(PROBS, M, NUM_SAMPLES, DEPTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the Distribution of $F_{i, n}$\n",
    "\n",
    "If we can find the probability distribution for $F_{i, n}$ then we can find the probability distribution of $X_{i, n}$ through the total law of probability.\n",
    "\n",
    "My first attempt at finding this is through a Markov Chain. Instead of indexing by $i$, let's consider that there is only one thread that we are following. Therefore we are looking at the random variable $F_n$. Furthermore, note that $F_n$ is closely tied to $F_{n - 1}$ since we rely on the parent state to determine what the child's failure transition is. This suggests that we should be looking at a first order Markov Chain.\n",
    "\n",
    "What is $P\\left(F_n = a | F_{n - 1} = b\\right)$? First I assert that this probability is 0 if $a > b + 1$. This can be proved via induction. Note that $F_1 = 1$ deterministically and that the most that $F_2$ can be is 2. Now assume that this is true for all states up to and including depth $n = k$. For $F_{k + 1}$ consider the following scenario where the $F_k = b$. The best we can do is go one previous link in the chain ($b - 1$) before matching with some parent's child. From the inductive hypothesis we see that this can have at most one greater ($b$). Adding a failure function to the newly added child we get $b + 1$.\n",
    "\n",
    "Finally note that there is a recursive aspect to this probability. If we want to find that the length of the failure chain is $a$, this means that we must consider the probability that the previous link in the chain had length $a - 1$. Therefore I think that the distribution is the following:\n",
    "\n",
    "$$\n",
    "P\\left(F_n = a | F_{n - 1} = b\\right) = \\begin{cases} \n",
    "      0 & a > b + 1 \\\\\n",
    "      \\alpha & a = 1, b = 1 \\\\\n",
    "      \\beta & a = 2, b = 1 \\\\\n",
    "      \\sum_{\\ell = 1}^{b - 1} P\\left(F_n = a - 1 | F_{n - 1} = b - L\\right) P(L = \\ell) & \\textrm{else}\n",
    "   \\end{cases}\n",
    "$$\n",
    "\n",
    "Here $L$ is an altered geometric random variable that describes how far down we fall before we are able to match with something.\n",
    "\n",
    "Because this Markov Chain is irreducible we know that there is at most one stationary distribution $\\pi$. However, we cannot guarantee that there is at least one because the state space is infinite. That being said, I am pretty sure that there exists one. If we were able to find such a $\\pi$ then we would have the probabilities needed to finish the calculation we started in the first part."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
